{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unity ML Agents\n",
    "## Proximal Policy Optimization (PPO)\n",
    "Contains an implementation of PPO as described [here](https://arxiv.org/abs/1707.06347)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from ppo.history import *\n",
    "from ppo.models import *\n",
    "from ppo.trainer import Trainer\n",
    "from unityagents import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### General parameters\n",
    "max_steps = 10000000 # Set maximum number of steps to run environment.\n",
    "run_path = \"Tennis_Z_4\" # The sub-directory name for model and summary statistics\n",
    "load_model = False # Whether to load a saved model.\n",
    "train_model = True # Whether to train the model.\n",
    "summary_freq = 1000 # Frequency at which to save training statistics.\n",
    "save_freq = 50000 # Frequency at which to save model.\n",
    "env_name = \"Tennis_Z\" # Name of the training environment file.\n",
    "curriculum_file = None\n",
    "\n",
    "### Algorithm-specific parameters for tuning\n",
    "gamma = 0.99 # Reward discount rate.\n",
    "lambd = 0.95 # Lambda parameter for GAE.\n",
    "time_horizon = 2048 # How many steps to collect per agent before adding to buffer.\n",
    "beta = 2.5e-3 # Strength of entropy regularization\n",
    "num_epoch = 5 # Number of gradient descent steps per batch of experiences.\n",
    "num_layers = 2 # Number of hidden layers between state/observation encoding and value/policy layers.\n",
    "epsilon = 0.2 # Acceptable threshold around ratio of old and new policy probabilities.\n",
    "buffer_size = 2048 # How large the experience buffer should be before gradient descent.\n",
    "learning_rate = 3e-4 # Model learning rate.\n",
    "hidden_units = 64 # Number of units in hidden layer.\n",
    "batch_size = 64 # How many experiences per gradient descent update step.\n",
    "normalize = False\n",
    "\n",
    "### Logging dictionary for hyperparameters\n",
    "hyperparameter_dict = {'max_steps':max_steps, 'run_path':run_path, 'env_name':env_name,\n",
    "    'curriculum_file':curriculum_file, 'gamma':gamma, 'lambd':lambd, 'time_horizon':time_horizon,\n",
    "    'beta':beta, 'num_epoch':num_epoch, 'epsilon':epsilon, 'buffe_size':buffer_size,\n",
    "    'leaning_rate':learning_rate, 'hidden_units':hidden_units, 'batch_size':batch_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unity Academy name: Academy\n",
      "        Number of brains: 2\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: MyBrain\n",
      "        Number of observations (per agent): 0\n",
      "        State space type: continuous\n",
      "        State space size (per agent): 12\n",
      "        Action space type: discrete\n",
      "        Action space size (per agent): 6\n",
      "        Memory space size (per agent): 0\n",
      "        Action descriptions: , , , , , \n",
      "Unity brain name: TennisBrain\n",
      "        Number of observations (per agent): 0\n",
      "        State space type: continuous\n",
      "        State space size (per agent): 12\n",
      "        Action space type: discrete\n",
      "        Action space size (per agent): 6\n",
      "        Memory space size (per agent): 0\n",
      "        Action descriptions: , , , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=env_name, curriculum=curriculum_file, worker_id=1)\n",
    "print(str(env))\n",
    "brain_name = env.external_brain_names[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Agent(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1000. Mean Reward: -0.027136752136752137. Std of Reward: 0.07803849652497628.\n",
      "Step: 2000. Mean Reward: -0.024904086738949123. Std of Reward: 0.08144833639326328.\n",
      "Step: 3000. Mean Reward: -0.025503715937241954. Std of Reward: 0.08154762193650911.\n",
      "Step: 4000. Mean Reward: -0.025004108463434677. Std of Reward: 0.08216825923784211.\n",
      "Step: 5000. Mean Reward: -0.02413382594417077. Std of Reward: 0.0825627898906324.\n",
      "Step: 6000. Mean Reward: -0.02465983606557377. Std of Reward: 0.08280808759091669.\n",
      "Step: 7000. Mean Reward: -0.024537643207855973. Std of Reward: 0.08263752000323545.\n",
      "Step: 8000. Mean Reward: -0.024087947882736153. Std of Reward: 0.08350417152791866.\n",
      "Step: 9000. Mean Reward: -0.02491823385118561. Std of Reward: 0.0825981753048072.\n",
      "Step: 10000. Mean Reward: -0.024747351263243685. Std of Reward: 0.08283582548889544.\n",
      "Step: 11000. Mean Reward: -0.024387755102040817. Std of Reward: 0.08272780948573082.\n",
      "Step: 12000. Mean Reward: -0.024677023712183156. Std of Reward: 0.08278397655227301.\n",
      "Step: 13000. Mean Reward: -0.025077614379084966. Std of Reward: 0.0823857528742789.\n",
      "Step: 14000. Mean Reward: -0.02563882063882064. Std of Reward: 0.08198662882084379.\n",
      "Step: 15000. Mean Reward: -0.024272875816993465. Std of Reward: 0.08315791762832146.\n",
      "Step: 16000. Mean Reward: -0.02353946297803092. Std of Reward: 0.08374281279555254.\n",
      "Step: 17000. Mean Reward: -0.02414963205233034. Std of Reward: 0.08324466013009679.\n",
      "Step: 18000. Mean Reward: -0.024396903015484923. Std of Reward: 0.08281876358936197.\n",
      "Step: 19000. Mean Reward: -0.02403501628664495. Std of Reward: 0.08340062888035181.\n",
      "Step: 20000. Mean Reward: -0.025151391162029458. Std of Reward: 0.08232068740594764.\n",
      "Step: 21000. Mean Reward: -0.023390663390663393. Std of Reward: 0.08409104818333638.\n",
      "Step: 22000. Mean Reward: -0.025518367346938773. Std of Reward: 0.08216308241308963.\n",
      "Step: 23000. Mean Reward: -0.025421095666394115. Std of Reward: 0.08203043796073063.\n",
      "Step: 24000. Mean Reward: -0.02593393148450245. Std of Reward: 0.08174723630256786.\n",
      "Step: 25000. Mean Reward: -0.025921696574225123. Std of Reward: 0.08155157538449273.\n",
      "Step: 26000. Mean Reward: -0.024326765188834153. Std of Reward: 0.08290892557764283.\n",
      "Step: 27000. Mean Reward: -0.02549795918367347. Std of Reward: 0.08187507280519192.\n",
      "Step: 28000. Mean Reward: -0.026166121112929625. Std of Reward: 0.08142394902086408.\n",
      "Step: 29000. Mean Reward: -0.024442636289666395. Std of Reward: 0.0829036870284528.\n",
      "Step: 30000. Mean Reward: -0.025327868852459016. Std of Reward: 0.08220311136696122.\n",
      "Step: 31000. Mean Reward: -0.02389754098360656. Std of Reward: 0.0835964996160222.\n",
      "Step: 32000. Mean Reward: -0.024082719082719084. Std of Reward: 0.08344937528441079.\n",
      "Step: 33000. Mean Reward: -0.02412613355317395. Std of Reward: 0.08343115353207084.\n",
      "Step: 34000. Mean Reward: -0.02461038961038961. Std of Reward: 0.08320786923389883.\n",
      "Step: 35000. Mean Reward: -0.026211072664359864. Std of Reward: 0.08175097482181189.\n",
      "Step: 36000. Mean Reward: -0.02560658578856153. Std of Reward: 0.08231025862024564.\n",
      "Step: 37000. Mean Reward: -0.024826989619377165. Std of Reward: 0.08301970311601024.\n",
      "Step: 38000. Mean Reward: -0.02285714285714286. Std of Reward: 0.0847536354738596.\n",
      "Step: 39000. Mean Reward: -0.024242424242424242. Std of Reward: 0.0835428299374033.\n",
      "Step: 40000. Mean Reward: -0.02577989601386482. Std of Reward: 0.08215072640496048.\n",
      "Step: 41000. Mean Reward: -0.024935064935064935. Std of Reward: 0.08292212029681581.\n",
      "Step: 42000. Mean Reward: -0.024935064935064935. Std of Reward: 0.08292212029681581.\n",
      "Step: 43000. Mean Reward: -0.02474003466204506. Std of Reward: 0.08309790435053786.\n",
      "Step: 44000. Mean Reward: -0.02461005199306759. Std of Reward: 0.08321462990560366.\n",
      "Step: 45000. Mean Reward: -0.024978354978354978. Std of Reward: 0.08288297941122642.\n",
      "Step: 46000. Mean Reward: -0.026147186147186148. Std of Reward: 0.0818104396346076.\n",
      "Step: 47000. Mean Reward: -0.024978354978354978. Std of Reward: 0.08288297941122642.\n",
      "Step: 48000. Mean Reward: -0.024740484429065745. Std of Reward: 0.08309759002689211.\n",
      "Step: 49000. Mean Reward: -0.025303292894280766. Std of Reward: 0.08258782336405895.\n",
      "Step: 50000. Mean Reward: -0.025951557093425604. Std of Reward: 0.08199213655011663.\n",
      "Saved Model\n",
      "INFO:tensorflow:Restoring parameters from ./models/Tennis_Z_4\\model-50000.cptk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/Tennis_Z_4\\model-50000.cptk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 4 variables to const ops.\n",
      "Step: 51000. Mean Reward: -0.024155844155844156. Std of Reward: 0.08361969127470005.\n",
      "Step: 52000. Mean Reward: -0.023982683982683984. Std of Reward: 0.08377293394683218.\n",
      "Step: 53000. Mean Reward: -0.025996533795493933. Std of Reward: 0.08195035899741492.\n",
      "Step: 54000. Mean Reward: -0.024112554112554113. Std of Reward: 0.0836580618605029.\n",
      "Step: 55000. Mean Reward: -0.025450216450216452. Std of Reward: 0.08245655231352854.\n",
      "Step: 56000. Mean Reward: -0.02365684575389948. Std of Reward: 0.08405952392394984.\n",
      "Step: 57000. Mean Reward: -0.025086655112651644. Std of Reward: 0.08278483383282557.\n",
      "Step: 58000. Mean Reward: -0.024025974025974027. Std of Reward: 0.08373468314174129.\n",
      "Step: 59000. Mean Reward: -0.02519047619047619. Std of Reward: 0.08269347297137553.\n",
      "Step: 60000. Mean Reward: -0.024675324675324677. Std of Reward: 0.08315610546422215.\n",
      "Step: 61000. Mean Reward: -0.02504325259515571. Std of Reward: 0.08282427011998665.\n",
      "Step: 62000. Mean Reward: -0.024783362218370884. Std of Reward: 0.08305891417572694.\n",
      "Step: 63000. Mean Reward: -0.02465397923875433. Std of Reward: 0.08317531403480541.\n",
      "Step: 64000. Mean Reward: -0.024935064935064935. Std of Reward: 0.08292212029681582.\n",
      "Step: 65000. Mean Reward: -0.02458874458874459. Std of Reward: 0.08323377422667445.\n",
      "Step: 66000. Mean Reward: -0.026256499133448873. Std of Reward: 0.08170851135986475.\n",
      "Step: 67000. Mean Reward: -0.02432900432900433. Std of Reward: 0.08346580801023164.\n",
      "Step: 68000. Mean Reward: -0.024324675324675325. Std of Reward: 0.08347251535505433.\n",
      "Step: 69000. Mean Reward: -0.025909878682842287. Std of Reward: 0.08203063334566546.\n",
      "Step: 70000. Mean Reward: -0.02482235701906413. Std of Reward: 0.08302665826086297.\n",
      "Step: 71000. Mean Reward: -0.024069264069264074. Std of Reward: 0.08369639246454783.\n",
      "Step: 72000. Mean Reward: -0.024848484848484852. Std of Reward: 0.0830002789587368.\n",
      "Step: 73000. Mean Reward: -0.025406926406926406. Std of Reward: 0.08248564741788092.\n",
      "Step: 74000. Mean Reward: -0.024217128027681663. Std of Reward: 0.08356819470850307.\n",
      "Step: 75000. Mean Reward: -0.025216637781629116. Std of Reward: 0.08266675202015644.\n",
      "Step: 76000. Mean Reward: -0.025908304498269898. Std of Reward: 0.08203218142391923.\n",
      "Step: 77000. Mean Reward: -0.02566666666666667. Std of Reward: 0.08225797066165527.\n",
      "Step: 78000. Mean Reward: -0.02480519480519481. Std of Reward: 0.0830392968509419.\n",
      "Step: 79000. Mean Reward: -0.02634315424610052. Std of Reward: 0.08162755226325814.\n",
      "Step: 80000. Mean Reward: -0.025324675324675326. Std of Reward: 0.08256836729991843.\n",
      "Step: 81000. Mean Reward: -0.026060606060606062. Std of Reward: 0.08189094087281748.\n",
      "Step: 82000. Mean Reward: -0.025. Std of Reward: 0.08286334828339269.\n",
      "Step: 83000. Mean Reward: -0.024436741767764298. Std of Reward: 0.08336969451625699.\n",
      "Step: 84000. Mean Reward: -0.025324675324675326. Std of Reward: 0.08256836729991843.\n",
      "Step: 85000. Mean Reward: -0.024458874458874458. Std of Reward: 0.08334997303934516.\n",
      "Step: 86000. Mean Reward: -0.025. Std of Reward: 0.08286343874694592.\n",
      "Step: 87000. Mean Reward: -0.02567099567099567. Std of Reward: 0.08225109364319812.\n",
      "Step: 88000. Mean Reward: -0.02577989601386482. Std of Reward: 0.08215072640496049.\n",
      "Step: 89000. Mean Reward: -0.023572664359861596. Std of Reward: 0.0841333022052505.\n",
      "Step: 90000. Mean Reward: -0.02536796536796537. Std of Reward: 0.0825288542731278.\n",
      "Step: 91000. Mean Reward: -0.025493934142114386. Std of Reward: 0.08242568449258957.\n",
      "Step: 92000. Mean Reward: -0.024653379549393416. Std of Reward: 0.08317576215814945.\n",
      "Step: 93000. Mean Reward: -0.02393847487001733. Std of Reward: 0.08375373258820973.\n",
      "Step: 94000. Mean Reward: -0.024930675909878686. Std of Reward: 0.08293805739233678.\n",
      "Step: 95000. Mean Reward: -0.023369565217391305. Std of Reward: 0.08428313016402361.\n",
      "Step: 96000. Mean Reward: -0.025447048611111113. Std of Reward: 0.08226328503169547.\n",
      "Step: 97000. Mean Reward: -0.0250995670995671. Std of Reward: 0.08272922268175184.\n",
      "Step: 98000. Mean Reward: -0.02482235701906413. Std of Reward: 0.08302665826086297.\n",
      "Step: 99000. Mean Reward: -0.02611785095320624. Std of Reward: 0.08170310187738772.\n",
      "Step: 100000. Mean Reward: -0.02500434782608696. Std of Reward: 0.0827056066563855.\n",
      "Saved Model\n",
      "INFO:tensorflow:Restoring parameters from ./models/Tennis_Z_4\\model-100000.cptk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/Tennis_Z_4\\model-100000.cptk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 4 variables to const ops.\n",
      "Step: 101000. Mean Reward: -0.024638186573670447. Std of Reward: 0.08302857591205796.\n",
      "Step: 102000. Mean Reward: -0.02605217391304348. Std of Reward: 0.0817758169289952.\n",
      "Step: 103000. Mean Reward: -0.025529513888888893. Std of Reward: 0.08206100053914721.\n",
      "Step: 104000. Mean Reward: -0.02470945359930616. Std of Reward: 0.08288555557271869.\n",
      "Step: 105000. Mean Reward: -0.024171725932350393. Std of Reward: 0.08353961516061832.\n",
      "Step: 106000. Mean Reward: -0.024241110147441458. Std of Reward: 0.08342703534643144.\n",
      "Step: 107000. Mean Reward: -0.025364583333333336. Std of Reward: 0.08234648424724607.\n",
      "Step: 108000. Mean Reward: -0.024948006932409013. Std of Reward: 0.08289522149875414.\n",
      "Step: 109000. Mean Reward: -0.025433275563258233. Std of Reward: 0.08246911801718498.\n",
      "Step: 110000. Mean Reward: -0.02560553633217993. Std of Reward: 0.08231131366277833.\n",
      "Step: 111000. Mean Reward: -0.025541125541125545. Std of Reward: 0.08237038511092384.\n",
      "Step: 112000. Mean Reward: -0.02543252595155709. Std of Reward: 0.08246989456484424.\n",
      "Step: 113000. Mean Reward: -0.02495242214532872. Std of Reward: 0.08289891175556999.\n",
      "Step: 114000. Mean Reward: -0.024995667244367418. Std of Reward: 0.08285968793190995.\n",
      "Step: 115000. Mean Reward: -0.025281629116117848. Std of Reward: 0.08254854393739966.\n",
      "Step: 116000. Mean Reward: -0.025259740259740263. Std of Reward: 0.08256859710348823.\n",
      "Step: 117000. Mean Reward: -0.024804856895056376. Std of Reward: 0.0829219274229042.\n",
      "Step: 118000. Mean Reward: -0.025363951473136914. Std of Reward: 0.08246577537247038.\n",
      "Step: 119000. Mean Reward: -0.024657415437987856. Std of Reward: 0.083034855527797.\n",
      "Step: 120000. Mean Reward: -0.0249609375. Std of Reward: 0.08277520513554892.\n",
      "Step: 121000. Mean Reward: -0.026003475238922675. Std of Reward: 0.08155427579864677.\n",
      "Step: 122000. Mean Reward: -0.02586371527777778. Std of Reward: 0.08194648386685763.\n",
      "Step: 123000. Mean Reward: -0.025004332755632585. Std of Reward: 0.0827702232684561.\n",
      "Step: 124000. Mean Reward: -0.02469895287958115. Std of Reward: 0.08268955239746054.\n",
      "Step: 125000. Mean Reward: -0.025030276816609. Std of Reward: 0.08281330850783188.\n",
      "Step: 126000. Mean Reward: -0.02487424111014744. Std of Reward: 0.08285038482848511.\n",
      "Step: 127000. Mean Reward: -0.024468177855274626. Std of Reward: 0.08297724285708498.\n",
      "Step: 128000. Mean Reward: -0.024280732345248475. Std of Reward: 0.0834222335672173.\n",
      "Step: 129000. Mean Reward: -0.024791304347826084. Std of Reward: 0.08272584325213578.\n",
      "Step: 130000. Mean Reward: -0.024280762564991336. Std of Reward: 0.08340382766241958.\n",
      "Step: 131000. Mean Reward: -0.02537793223284101. Std of Reward: 0.08232930950589461.\n",
      "Step: 132000. Mean Reward: -0.024560104529616725. Std of Reward: 0.0828792510526087.\n",
      "Step: 133000. Mean Reward: -0.02486979166666667. Std of Reward: 0.08265862522185878.\n",
      "Step: 134000. Mean Reward: -0.025217770034843205. Std of Reward: 0.08236722795940842.\n",
      "Step: 135000. Mean Reward: -0.024838709677419357. Std of Reward: 0.08234861761072763.\n",
      "Step: 136000. Mean Reward: -0.02439301310043668. Std of Reward: 0.08266152980761486.\n",
      "Step: 137000. Mean Reward: -0.024404031551270813. Std of Reward: 0.08282702026581024.\n",
      "Step: 138000. Mean Reward: -0.023645104895104897. Std of Reward: 0.08355308973765889.\n",
      "Step: 139000. Mean Reward: -0.023893263342082242. Std of Reward: 0.0835669951328114.\n",
      "Step: 140000. Mean Reward: -0.025283101045296165. Std of Reward: 0.0816772563765388.\n",
      "Step: 141000. Mean Reward: -0.02424017467248908. Std of Reward: 0.08313593830302317.\n",
      "Step: 142000. Mean Reward: -0.02292502179598954. Std of Reward: 0.08415090314623168.\n",
      "Step: 143000. Mean Reward: -0.02384279475982533. Std of Reward: 0.08328092985659344.\n",
      "Step: 144000. Mean Reward: -0.02443421052631579. Std of Reward: 0.08276173296684271.\n",
      "Step: 145000. Mean Reward: -0.024511343804537525. Std of Reward: 0.08283837136313375.\n",
      "Step: 146000. Mean Reward: -0.024073107049608355. Std of Reward: 0.08320253194480301.\n",
      "Step: 147000. Mean Reward: -0.025603146853146852. Std of Reward: 0.08167597495715745.\n",
      "Step: 148000. Mean Reward: -0.024593175853018373. Std of Reward: 0.08252514040324545.\n",
      "Step: 149000. Mean Reward: -0.024426946631671043. Std of Reward: 0.08263433692832133.\n",
      "Step: 150000. Mean Reward: -0.0240377855887522. Std of Reward: 0.08287134233669162.\n",
      "Saved Model\n",
      "INFO:tensorflow:Restoring parameters from ./models/Tennis_Z_4\\model-150000.cptk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/Tennis_Z_4\\model-150000.cptk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 4 variables to const ops.\n",
      "Step: 151000. Mean Reward: -0.024833625218914183. Std of Reward: 0.08249512212290615.\n",
      "Step: 152000. Mean Reward: -0.024540682414698162. Std of Reward: 0.08253758579792957.\n",
      "Step: 153000. Mean Reward: -0.02491703056768559. Std of Reward: 0.0822394900727565.\n",
      "Step: 154000. Mean Reward: -0.02452048823016565. Std of Reward: 0.08270761975107281.\n",
      "Step: 155000. Mean Reward: -0.02487772925764192. Std of Reward: 0.08221288736562049.\n",
      "Step: 156000. Mean Reward: -0.024221347331583553. Std of Reward: 0.0830487634591597.\n",
      "Step: 157000. Mean Reward: -0.024846356453028972. Std of Reward: 0.0823227769636418.\n",
      "Step: 158000. Mean Reward: -0.024166666666666666. Std of Reward: 0.08315209348862838.\n",
      "Step: 159000. Mean Reward: -0.025253496503496505. Std of Reward: 0.08215586460608315.\n",
      "Step: 160000. Mean Reward: -0.025048076923076923. Std of Reward: 0.0821179294184048.\n",
      "Step: 161000. Mean Reward: -0.025061349693251536. Std of Reward: 0.0824441526402948.\n",
      "Step: 162000. Mean Reward: -0.024563318777292575. Std of Reward: 0.08296369837690679.\n",
      "Step: 163000. Mean Reward: -0.024930191972076788. Std of Reward: 0.08251153822407363.\n",
      "Step: 164000. Mean Reward: -0.023892794376098418. Std of Reward: 0.08342016231458775.\n",
      "Step: 165000. Mean Reward: -0.024916512059369202. Std of Reward: 0.08285906002084156.\n",
      "Step: 166000. Mean Reward: -0.026493023255813954. Std of Reward: 0.08139298122802424.\n",
      "Step: 167000. Mean Reward: -0.025567970204841712. Std of Reward: 0.08223090269299545.\n",
      "Step: 168000. Mean Reward: -0.023438661710037174. Std of Reward: 0.08416535852655858.\n",
      "Step: 169000. Mean Reward: -0.024864864864864864. Std of Reward: 0.08273350363585105.\n",
      "Step: 170000. Mean Reward: -0.02554883720930233. Std of Reward: 0.08224552683699235.\n",
      "Step: 171000. Mean Reward: -0.02405140186915888. Std of Reward: 0.08346518202331016.\n",
      "Step: 172000. Mean Reward: -0.02403180542563143. Std of Reward: 0.08350385190006124.\n",
      "Step: 173000. Mean Reward: -0.024316914498141263. Std of Reward: 0.08336051687327345.\n",
      "Step: 174000. Mean Reward: -0.024471468662301217. Std of Reward: 0.08321040975544489.\n",
      "Step: 175000. Mean Reward: -0.025311918063314714. Std of Reward: 0.0824132380947808.\n",
      "Step: 176000. Mean Reward: -0.02265639589169001. Std of Reward: 0.0847580868713519.\n",
      "Step: 177000. Mean Reward: -0.024601113172541746. Std of Reward: 0.08311524108833904.\n",
      "Step: 178000. Mean Reward: -0.025315985130111525. Std of Reward: 0.08243163532794875.\n",
      "Step: 179000. Mean Reward: -0.024130028063610854. Std of Reward: 0.08348924817822338.\n",
      "Step: 180000. Mean Reward: -0.02575955265610438. Std of Reward: 0.08201167127964981.\n",
      "Step: 181000. Mean Reward: -0.024642193308550185. Std of Reward: 0.08306938384261901.\n",
      "Step: 182000. Mean Reward: -0.024668534080298787. Std of Reward: 0.08298333970237161.\n",
      "Step: 183000. Mean Reward: -0.02452690166975881. Std of Reward: 0.08321356791313834.\n",
      "Step: 184000. Mean Reward: -0.024614670380687095. Std of Reward: 0.08307219113421942.\n",
      "Step: 185000. Mean Reward: -0.024976744186046514. Std of Reward: 0.08274294415842554.\n",
      "Step: 186000. Mean Reward: -0.024323062558356673. Std of Reward: 0.08337637107337927.\n",
      "Step: 187000. Mean Reward: -0.024706976744186045. Std of Reward: 0.08301405147336634.\n",
      "Step: 188000. Mean Reward: -0.02409981343283582. Std of Reward: 0.08340990380167093.\n",
      "Step: 189000. Mean Reward: -0.02470533208606174. Std of Reward: 0.0828482229413175.\n",
      "Step: 190000. Mean Reward: -0.02430102516309413. Std of Reward: 0.08333228139743072.\n",
      "Step: 191000. Mean Reward: -0.025961895910780672. Std of Reward: 0.08183765572035463.\n",
      "Step: 192000. Mean Reward: -0.026158536585365853. Std of Reward: 0.08161605997068204.\n",
      "Step: 193000. Mean Reward: -0.024547574626865673. Std of Reward: 0.08286599376838513.\n",
      "Step: 194000. Mean Reward: -0.025455840455840456. Std of Reward: 0.08231056813303445.\n",
      "Step: 195000. Mean Reward: -0.02571. Std of Reward: 0.08207128547793072.\n",
      "Step: 196000. Mean Reward: -0.02506. Std of Reward: 0.08262382465124694.\n",
      "Step: 197000. Mean Reward: -0.0249402390438247. Std of Reward: 0.08277192548051317.\n",
      "Step: 198000. Mean Reward: -0.02411764705882353. Std of Reward: 0.08350911806054061.\n",
      "Step: 199000. Mean Reward: -0.02627254509018036. Std of Reward: 0.08152193274679531.\n",
      "Step: 200000. Mean Reward: -0.02461615154536391. Std of Reward: 0.0830640014286871.\n",
      "Saved Model\n",
      "INFO:tensorflow:Restoring parameters from ./models/Tennis_Z_4\\model-200000.cptk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/Tennis_Z_4\\model-200000.cptk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 4 variables to const ops.\n",
      "Step: 201000. Mean Reward: -0.02434262948207171. Std of Reward: 0.08330909024463425.\n",
      "Step: 202000. Mean Reward: -0.024331337325349305. Std of Reward: 0.08331338281749814.\n",
      "Step: 203000. Mean Reward: -0.025434131736526946. Std of Reward: 0.08231288071760429.\n",
      "Step: 204000. Mean Reward: -0.025891434262948206. Std of Reward: 0.08190949581286283.\n",
      "Step: 205000. Mean Reward: -0.025743512974051898. Std of Reward: 0.08204592017157666.\n",
      "Step: 206000. Mean Reward: -0.024626121635094714. Std of Reward: 0.08307244850437252.\n",
      "Step: 207000. Mean Reward: -0.02525974025974026. Std of Reward: 0.08248426403695888.\n",
      "Step: 208000. Mean Reward: -0.023448103792415166. Std of Reward: 0.0841070081726232.\n",
      "Step: 209000. Mean Reward: -0.026335. Std of Reward: 0.08147771336383958.\n",
      "Step: 210000. Mean Reward: -0.026394422310756973. Std of Reward: 0.08144944297979004.\n",
      "Step: 211000. Mean Reward: -0.025199203187250996. Std of Reward: 0.08255422073955329.\n",
      "Step: 212000. Mean Reward: -0.025674325674325673. Std of Reward: 0.0821183682483162.\n",
      "Step: 213000. Mean Reward: -0.023579262213359924. Std of Reward: 0.08400108274864797.\n",
      "Step: 214000. Mean Reward: -0.025448207171314737. Std of Reward: 0.08232671229040257.\n",
      "Step: 215000. Mean Reward: -0.02437686939182453. Std of Reward: 0.08329568434366245.\n",
      "Step: 216000. Mean Reward: -0.025298804780876493. Std of Reward: 0.0824633829071049.\n",
      "Step: 217000. Mean Reward: -0.024153386454183266. Std of Reward: 0.08349487888061699.\n",
      "Step: 218000. Mean Reward: -0.024500998003992015. Std of Reward: 0.08318450081985646.\n",
      "Step: 219000. Mean Reward: -0.024626121635094717. Std of Reward: 0.08307244850437254.\n",
      "Step: 220000. Mean Reward: -0.02392107892107892. Std of Reward: 0.08369143032428733.\n",
      "Step: 221000. Mean Reward: -0.025798403193612776. Std of Reward: 0.08200403620272623.\n",
      "Step: 222000. Mean Reward: -0.024470529470529467. Std of Reward: 0.08320289453474813.\n",
      "Step: 223000. Mean Reward: -0.0249402390438247. Std of Reward: 0.08277192548051317.\n",
      "Step: 224000. Mean Reward: -0.024620758483033935. Std of Reward: 0.08303683313391555.\n",
      "Step: 225000. Mean Reward: -0.025394211576846307. Std of Reward: 0.08236701788432571.\n",
      "Step: 226000. Mean Reward: -0.02452642073778664. Std of Reward: 0.08316190439631589.\n",
      "Step: 227000. Mean Reward: -0.024945219123505977. Std of Reward: 0.08277614045928001.\n",
      "Step: 228000. Mean Reward: -0.02429640718562874. Std of Reward: 0.08335860275795386.\n",
      "Step: 229000. Mean Reward: -0.02564741035856574. Std of Reward: 0.0821437083893533.\n",
      "Step: 230000. Mean Reward: -0.024651394422310756. Std of Reward: 0.08304991771649713.\n",
      "Step: 231000. Mean Reward: -0.025505505505505507. Std of Reward: 0.0822623048943211.\n",
      "Step: 232000. Mean Reward: -0.02452642073778664. Std of Reward: 0.08316190439631589.\n",
      "Step: 233000. Mean Reward: -0.02435129740518962. Std of Reward: 0.08331833204286176.\n",
      "Step: 234000. Mean Reward: -0.02330677290836653. Std of Reward: 0.08423916290938278.\n",
      "Step: 235000. Mean Reward: -0.024735. Std of Reward: 0.08294775328482383.\n",
      "Step: 236000. Mean Reward: -0.022958167330677293. Std of Reward: 0.08454126413569438.\n",
      "Step: 237000. Mean Reward: -0.023942115768463074. Std of Reward: 0.08366438420466549.\n",
      "Step: 238000. Mean Reward: -0.02383. Std of Reward: 0.0837462303629244.\n",
      "Step: 239000. Mean Reward: -0.02572. Std of Reward: 0.08204926325080562.\n",
      "Step: 240000. Mean Reward: -0.024545. Std of Reward: 0.08307402105953463.\n",
      "Step: 241000. Mean Reward: -0.025410821643286573. Std of Reward: 0.08216132014629887.\n",
      "Step: 242000. Mean Reward: -0.024481037924151697. Std of Reward: 0.08317957955418467.\n",
      "Step: 243000. Mean Reward: -0.025295887662988965. Std of Reward: 0.08233574702919738.\n",
      "Step: 244000. Mean Reward: -0.026775653923541247. Std of Reward: 0.08084573064675585.\n",
      "Step: 245000. Mean Reward: -0.02527162977867203. Std of Reward: 0.08229466037793752.\n",
      "Step: 246000. Mean Reward: -0.023741188318227597. Std of Reward: 0.08365367322903855.\n",
      "Step: 247000. Mean Reward: -0.02463855421686747. Std of Reward: 0.08278273857964022.\n",
      "Step: 248000. Mean Reward: -0.024075757575757577. Std of Reward: 0.08336426285522938.\n",
      "Step: 249000. Mean Reward: -0.02379275653923541. Std of Reward: 0.08354206706603012.\n",
      "Step: 250000. Mean Reward: -0.02391019172552977. Std of Reward: 0.0833475817375468.\n",
      "Saved Model\n",
      "INFO:tensorflow:Restoring parameters from ./models/Tennis_Z_4\\model-250000.cptk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/Tennis_Z_4\\model-250000.cptk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 4 variables to const ops.\n",
      "Step: 251000. Mean Reward: -0.024623115577889446. Std of Reward: 0.08292355060273608.\n",
      "Step: 252000. Mean Reward: -0.02317404426559356. Std of Reward: 0.08392913971501116.\n",
      "Step: 253000. Mean Reward: -0.02501010101010101. Std of Reward: 0.08241279381769727.\n",
      "Step: 254000. Mean Reward: -0.024120934959349593. Std of Reward: 0.08300773551436887.\n",
      "Step: 255000. Mean Reward: -0.023579373104145603. Std of Reward: 0.08352042440887832.\n",
      "Step: 256000. Mean Reward: -0.023293051359516617. Std of Reward: 0.08387836900874596.\n",
      "Step: 257000. Mean Reward: -0.022996926229508198. Std of Reward: 0.08357462057147906.\n",
      "Step: 258000. Mean Reward: -0.024502032520325203. Std of Reward: 0.08254190852249255.\n",
      "Step: 259000. Mean Reward: -0.02469450101832994. Std of Reward: 0.08215378722805124.\n",
      "Step: 260000. Mean Reward: -0.024136874361593463. Std of Reward: 0.08259730176137103.\n",
      "Step: 261000. Mean Reward: -0.022786377708978327. Std of Reward: 0.08350906206540777.\n",
      "Step: 262000. Mean Reward: -0.023752620545073374. Std of Reward: 0.08278603687783209.\n",
      "Step: 263000. Mean Reward: -0.022979568671963678. Std of Reward: 0.08215409120514681.\n",
      "Step: 264000. Mean Reward: -0.022408675799086758. Std of Reward: 0.08308559770342318.\n",
      "Step: 265000. Mean Reward: -0.02257687576875769. Std of Reward: 0.0822810669559837.\n",
      "Step: 266000. Mean Reward: -0.0237546468401487. Std of Reward: 0.08133507590568068.\n",
      "Step: 267000. Mean Reward: -0.022135862913096695. Std of Reward: 0.08219914111188012.\n",
      "Step: 268000. Mean Reward: -0.024586028460543335. Std of Reward: 0.0804112370834949.\n",
      "Step: 269000. Mean Reward: -0.022466032608695653. Std of Reward: 0.08194207052731389.\n",
      "Step: 270000. Mean Reward: -0.021711956521739132. Std of Reward: 0.08361355639824995.\n",
      "Step: 271000. Mean Reward: -0.023665768194070083. Std of Reward: 0.08050823324751509.\n",
      "Step: 272000. Mean Reward: -0.02294316644113667. Std of Reward: 0.08158070141288505.\n",
      "Step: 273000. Mean Reward: -0.021974393530997303. Std of Reward: 0.08304804501592092.\n",
      "Step: 274000. Mean Reward: -0.02260544217687075. Std of Reward: 0.08222220249195232.\n",
      "Step: 275000. Mean Reward: -0.02297699594046008. Std of Reward: 0.08188700264928257.\n",
      "Step: 276000. Mean Reward: -0.022216142270861834. Std of Reward: 0.08225290359509388.\n",
      "Step: 277000. Mean Reward: -0.022558299039780523. Std of Reward: 0.08255836171801226.\n",
      "Step: 278000. Mean Reward: -0.024218106995884774. Std of Reward: 0.08050406460772282.\n",
      "Step: 279000. Mean Reward: -0.02253396739130435. Std of Reward: 0.08145270826174443.\n",
      "Step: 280000. Mean Reward: -0.02473505434782609. Std of Reward: 0.08050746265366851.\n",
      "Step: 281000. Mean Reward: -0.023766666666666672. Std of Reward: 0.08150999257078172.\n",
      "Step: 282000. Mean Reward: -0.023690313778990453. Std of Reward: 0.08049020769695753.\n",
      "Step: 283000. Mean Reward: -0.022083333333333333. Std of Reward: 0.08428279676036565.\n",
      "Step: 284000. Mean Reward: -0.02292286874154263. Std of Reward: 0.08207629213980427.\n",
      "Step: 285000. Mean Reward: -0.023887399463806972. Std of Reward: 0.08106633947691405.\n",
      "Step: 286000. Mean Reward: -0.022258953168044077. Std of Reward: 0.08271724312166083.\n",
      "Step: 287000. Mean Reward: -0.022540983606557378. Std of Reward: 0.08223046523789203.\n",
      "Step: 288000. Mean Reward: -0.022248322147651007. Std of Reward: 0.08314928807826959.\n",
      "Step: 289000. Mean Reward: -0.02536734693877551. Std of Reward: 0.08051767724384243.\n",
      "Step: 290000. Mean Reward: -0.022428765264586162. Std of Reward: 0.08189539369866218.\n",
      "Step: 291000. Mean Reward: -0.02219512195121951. Std of Reward: 0.08318314842662966.\n",
      "Step: 292000. Mean Reward: -0.02385598923283984. Std of Reward: 0.08114674900007503.\n",
      "Step: 293000. Mean Reward: -0.024096385542168676. Std of Reward: 0.08201336179574713.\n",
      "Step: 294000. Mean Reward: -0.02486631016042781. Std of Reward: 0.0803259289040564.\n",
      "Step: 295000. Mean Reward: -0.023707250341997266. Std of Reward: 0.08121893998829595.\n",
      "Step: 296000. Mean Reward: -0.024068825910931176. Std of Reward: 0.08168504150231057.\n",
      "Step: 297000. Mean Reward: -0.021890080428954427. Std of Reward: 0.08394459894767994.\n",
      "Step: 298000. Mean Reward: -0.022864864864864866. Std of Reward: 0.08238199165658756.\n",
      "Step: 299000. Mean Reward: -0.023524699599465952. Std of Reward: 0.08231379271648046.\n",
      "Step: 300000. Mean Reward: -0.023670715249662615. Std of Reward: 0.08216713534167812.\n",
      "Saved Model\n",
      "INFO:tensorflow:Restoring parameters from ./models/Tennis_Z_4\\model-300000.cptk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/Tennis_Z_4\\model-300000.cptk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 4 variables to const ops.\n",
      "Step: 301000. Mean Reward: -0.022943121693121692. Std of Reward: 0.08301129484435546.\n",
      "Step: 302000. Mean Reward: -0.023768606224627876. Std of Reward: 0.08177045027460421.\n",
      "Step: 303000. Mean Reward: -0.022456021650879565. Std of Reward: 0.0829275922054298.\n",
      "Step: 304000. Mean Reward: -0.022586666666666665. Std of Reward: 0.08256376821719211.\n",
      "Step: 305000. Mean Reward: -0.023787262872628726. Std of Reward: 0.0819996083693388.\n",
      "Step: 306000. Mean Reward: -0.021793478260869564. Std of Reward: 0.0837798665815567.\n",
      "Step: 307000. Mean Reward: -0.023435374149659866. Std of Reward: 0.08230254193239406.\n",
      "Step: 308000. Mean Reward: -0.023519515477792734. Std of Reward: 0.08143023723225074.\n",
      "Step: 309000. Mean Reward: -0.022799174690508944. Std of Reward: 0.08260505527813164.\n",
      "Step: 310000. Mean Reward: -0.02241758241758242. Std of Reward: 0.0821905205536537.\n",
      "Step: 311000. Mean Reward: -0.022017783857729137. Std of Reward: 0.08199107229110003.\n",
      "Step: 312000. Mean Reward: -0.02356267029972752. Std of Reward: 0.08149433387607338.\n",
      "Step: 313000. Mean Reward: -0.023583892617449666. Std of Reward: 0.081410641973014.\n",
      "Step: 314000. Mean Reward: -0.02282520325203252. Std of Reward: 0.08261773606983898.\n",
      "Step: 315000. Mean Reward: -0.023210818307905685. Std of Reward: 0.08286661035551675.\n",
      "Step: 316000. Mean Reward: -0.024414965987755107. Std of Reward: 0.08023878848341462.\n",
      "Step: 317000. Mean Reward: -0.025336473755047106. Std of Reward: 0.0799115500401957.\n",
      "Step: 318000. Mean Reward: -0.02252688172043011. Std of Reward: 0.08253745860560545.\n",
      "Step: 319000. Mean Reward: -0.02371099050203528. Std of Reward: 0.0812946501130964.\n",
      "Step: 320000. Mean Reward: -0.023367346938775513. Std of Reward: 0.08154557856044181.\n",
      "Step: 321000. Mean Reward: -0.02257718120805369. Std of Reward: 0.08208321045764644.\n",
      "Step: 322000. Mean Reward: -0.02414965986394558. Std of Reward: 0.08096983176681852.\n",
      "Step: 323000. Mean Reward: -0.022123473541383987. Std of Reward: 0.08243024075824555.\n",
      "Step: 324000. Mean Reward: -0.02171703296703297. Std of Reward: 0.08251667920633181.\n",
      "Step: 325000. Mean Reward: -0.022275815217391304. Std of Reward: 0.08210824319079602.\n",
      "Step: 326000. Mean Reward: -0.02167994687915007. Std of Reward: 0.08359791888217936.\n",
      "Step: 327000. Mean Reward: -0.024565789473684214. Std of Reward: 0.08175828229835026.\n",
      "Step: 328000. Mean Reward: -0.022215528781793847. Std of Reward: 0.08270108186872288.\n",
      "Step: 329000. Mean Reward: -0.023100929614873842. Std of Reward: 0.08242191628039451.\n",
      "Step: 330000. Mean Reward: -0.02344782034346103. Std of Reward: 0.08216361861019926.\n",
      "Step: 331000. Mean Reward: -0.022969374167776297. Std of Reward: 0.0821642852326003.\n",
      "Step: 332000. Mean Reward: -0.02363576158940397. Std of Reward: 0.08245785465288559.\n",
      "Step: 333000. Mean Reward: -0.024143426294820716. Std of Reward: 0.08162910085373226.\n",
      "Step: 334000. Mean Reward: -0.022617765814266486. Std of Reward: 0.08239809518936794.\n",
      "Step: 335000. Mean Reward: -0.023149134487350197. Std of Reward: 0.08224708881024023.\n",
      "Step: 336000. Mean Reward: -0.02322386058981233. Std of Reward: 0.08147843524040292.\n",
      "Step: 337000. Mean Reward: -0.023125845737483084. Std of Reward: 0.08244142790065113.\n",
      "Step: 338000. Mean Reward: -0.0214850136239782. Std of Reward: 0.0833861159055706.\n",
      "Step: 339000. Mean Reward: -0.02153324287652646. Std of Reward: 0.0834383841883908.\n",
      "Step: 340000. Mean Reward: -0.02241144414168937. Std of Reward: 0.08304517453438093.\n",
      "Step: 341000. Mean Reward: -0.021947439353099736. Std of Reward: 0.08326261469334523.\n",
      "Step: 342000. Mean Reward: -0.023694481830417228. Std of Reward: 0.08134062311172635.\n",
      "Step: 343000. Mean Reward: -0.021917900403768505. Std of Reward: 0.08305827456868194.\n",
      "Step: 344000. Mean Reward: -0.022577597840755737. Std of Reward: 0.08289935679963013.\n",
      "Step: 345000. Mean Reward: -0.024133064516129035. Std of Reward: 0.08140847511602381.\n",
      "Step: 346000. Mean Reward: -0.024009433962264154. Std of Reward: 0.08099301102890705.\n",
      "Step: 347000. Mean Reward: -0.024401650618982116. Std of Reward: 0.08122272872570582.\n",
      "Step: 348000. Mean Reward: -0.02200303490136571. Std of Reward: 0.08257939568500029.\n",
      "Step: 349000. Mean Reward: -0.02187022900763359. Std of Reward: 0.08335300604960093.\n",
      "Step: 350000. Mean Reward: -0.022879699248120302. Std of Reward: 0.08289440130871688.\n",
      "Saved Model\n",
      "INFO:tensorflow:Restoring parameters from ./models/Tennis_Z_4\\model-350000.cptk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/Tennis_Z_4\\model-350000.cptk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 4 variables to const ops.\n",
      "Step: 351000. Mean Reward: -0.022410179640718564. Std of Reward: 0.08239146018093242.\n",
      "Step: 352000. Mean Reward: -0.022068452380952383. Std of Reward: 0.08270379636582086.\n",
      "Step: 353000. Mean Reward: -0.02373692077727952. Std of Reward: 0.08177183702491159.\n",
      "Step: 354000. Mean Reward: -0.02336053412462908. Std of Reward: 0.08188649586504455.\n",
      "Step: 355000. Mean Reward: -0.022578710644677664. Std of Reward: 0.08206083070849605.\n",
      "Step: 356000. Mean Reward: -0.023164179104477614. Std of Reward: 0.08181150468578974.\n",
      "Step: 357000. Mean Reward: -0.02297761194029851. Std of Reward: 0.0819556638802857.\n",
      "Step: 358000. Mean Reward: -0.02264359351988218. Std of Reward: 0.08260580085711701.\n",
      "Step: 359000. Mean Reward: -0.022312312312312312. Std of Reward: 0.0827106378174339.\n",
      "Step: 360000. Mean Reward: -0.02477645305514158. Std of Reward: 0.08048605573851397.\n",
      "Step: 361000. Mean Reward: -0.021792592592592593. Std of Reward: 0.08346594748503584.\n",
      "Step: 362000. Mean Reward: -0.02224137931034483. Std of Reward: 0.08225093372629352.\n",
      "Step: 363000. Mean Reward: -0.021221719457013576. Std of Reward: 0.08338800988100904.\n",
      "Step: 364000. Mean Reward: -0.021463046757164404. Std of Reward: 0.08236127643606127.\n",
      "Step: 365000. Mean Reward: -0.023417910447761193. Std of Reward: 0.0820245047574711.\n",
      "Step: 366000. Mean Reward: -0.02429166666666667. Std of Reward: 0.08116751154591076.\n",
      "Step: 367000. Mean Reward: -0.024119601328903655. Std of Reward: 0.08120544665201972.\n",
      "Step: 368000. Mean Reward: -0.02311165845648604. Std of Reward: 0.08199136290794534.\n",
      "Step: 369000. Mean Reward: -0.023515100671140942. Std of Reward: 0.08189334470027414.\n",
      "Step: 370000. Mean Reward: -0.022676174496644295. Std of Reward: 0.0819219785728164.\n",
      "Step: 371000. Mean Reward: -0.021464646464646464. Std of Reward: 0.08343050655202935.\n",
      "Step: 372000. Mean Reward: -0.022045075125208684. Std of Reward: 0.08312695987092075.\n",
      "Step: 373000. Mean Reward: -0.02420741989881956. Std of Reward: 0.08060743762578204.\n",
      "Step: 374000. Mean Reward: -0.022710437710437712. Std of Reward: 0.08249207895129933.\n",
      "Step: 375000. Mean Reward: -0.021376068376068376. Std of Reward: 0.08305020894046658.\n",
      "Step: 376000. Mean Reward: -0.022883333333333335. Std of Reward: 0.08241775530120247.\n",
      "Step: 377000. Mean Reward: -0.022170608108108107. Std of Reward: 0.08283674893399988.\n",
      "Step: 378000. Mean Reward: -0.022270450751252086. Std of Reward: 0.08198509766228852.\n",
      "Step: 379000. Mean Reward: -0.022123966942148764. Std of Reward: 0.082953942239195.\n",
      "Step: 380000. Mean Reward: -0.022764505119453923. Std of Reward: 0.0817619693224513.\n",
      "Step: 381000. Mean Reward: -0.022953216374269007. Std of Reward: 0.08197698385198009.\n",
      "Step: 382000. Mean Reward: -0.023607954545454547. Std of Reward: 0.08160762607559972.\n",
      "Step: 383000. Mean Reward: -0.02067490494296578. Std of Reward: 0.08395533857916086.\n",
      "Step: 384000. Mean Reward: -0.022844827586206897. Std of Reward: 0.08156897078128995.\n",
      "Step: 385000. Mean Reward: -0.023013182674199623. Std of Reward: 0.08165864030338903.\n",
      "Step: 386000. Mean Reward: -0.0215406427221172. Std of Reward: 0.08319465384004086.\n",
      "Step: 387000. Mean Reward: -0.021468926553672316. Std of Reward: 0.08350213679830891.\n",
      "Step: 388000. Mean Reward: -0.02407547169811321. Std of Reward: 0.08082122107293913.\n",
      "Step: 389000. Mean Reward: -0.02405123339658444. Std of Reward: 0.08068257921980634.\n",
      "Step: 390000. Mean Reward: -0.023796992481203007. Std of Reward: 0.08177116055017043.\n",
      "Step: 391000. Mean Reward: -0.02451612903225807. Std of Reward: 0.08117205486666867.\n",
      "Step: 392000. Mean Reward: -0.02359732824427481. Std of Reward: 0.08109424632336658.\n",
      "Step: 393000. Mean Reward: -0.02489443378119002. Std of Reward: 0.07987897748389908.\n",
      "Step: 394000. Mean Reward: -0.021500956022944554. Std of Reward: 0.08247337770261841.\n",
      "Step: 395000. Mean Reward: -0.022844990548204158. Std of Reward: 0.08256598769273374.\n",
      "Step: 396000. Mean Reward: -0.02213345864661654. Std of Reward: 0.0833478141803327.\n",
      "Step: 397000. Mean Reward: -0.022077798861480077. Std of Reward: 0.08204773463954605.\n",
      "Step: 398000. Mean Reward: -0.023342857142857144. Std of Reward: 0.08161212895052265.\n",
      "Step: 399000. Mean Reward: -0.02244296577946768. Std of Reward: 0.08250026833662301.\n",
      "Step: 400000. Mean Reward: -0.020952830188679245. Std of Reward: 0.08297384016885918.\n",
      "Saved Model\n",
      "INFO:tensorflow:Restoring parameters from ./models/Tennis_Z_4\\model-400000.cptk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/Tennis_Z_4\\model-400000.cptk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 4 variables to const ops.\n",
      "Step: 401000. Mean Reward: -0.02203422053231939. Std of Reward: 0.08286600324834309.\n",
      "Step: 402000. Mean Reward: -0.023333333333333334. Std of Reward: 0.08191745897835263.\n",
      "Step: 403000. Mean Reward: -0.02262693156732892. Std of Reward: 0.081523489639434.\n",
      "Step: 404000. Mean Reward: -0.023300438596491228. Std of Reward: 0.08111858927596945.\n",
      "Step: 405000. Mean Reward: -0.022571743929359823. Std of Reward: 0.08215171877056932.\n",
      "Step: 406000. Mean Reward: -0.021488888888888887. Std of Reward: 0.0833466981875433.\n",
      "Step: 407000. Mean Reward: -0.020951859956236323. Std of Reward: 0.08229125758074846.\n",
      "Step: 408000. Mean Reward: -0.022070484581497796. Std of Reward: 0.08266158577719945.\n",
      "Step: 409000. Mean Reward: -0.02339246119733925. Std of Reward: 0.08040514834935758.\n",
      "Step: 410000. Mean Reward: -0.020695652173913042. Std of Reward: 0.08433985843138962.\n",
      "Step: 411000. Mean Reward: -0.023211920529801325. Std of Reward: 0.081207453191979.\n",
      "Step: 412000. Mean Reward: -0.023212719298245615. Std of Reward: 0.08115454401115227.\n",
      "Step: 413000. Mean Reward: -0.02376379690949227. Std of Reward: 0.08142810214894527.\n",
      "Step: 414000. Mean Reward: -0.02058823529411765. Std of Reward: 0.08381483347471043.\n",
      "Step: 415000. Mean Reward: -0.023099352051835855. Std of Reward: 0.08232321106160626.\n",
      "Step: 416000. Mean Reward: -0.020075431034482758. Std of Reward: 0.08463215741536857.\n",
      "Step: 417000. Mean Reward: -0.025010729613733903. Std of Reward: 0.0800435764680866.\n",
      "Step: 418000. Mean Reward: -0.02348290598290598. Std of Reward: 0.08252457369384066.\n",
      "Step: 419000. Mean Reward: -0.024989247311827955. Std of Reward: 0.08136503365441447.\n",
      "Step: 420000. Mean Reward: -0.02388059701492537. Std of Reward: 0.08260339277369058.\n",
      "Step: 421000. Mean Reward: -0.023586723768736616. Std of Reward: 0.0820396080986196.\n",
      "Step: 422000. Mean Reward: -0.02536559139784946. Std of Reward: 0.08070339761088484.\n",
      "Step: 423000. Mean Reward: -0.022946808510638298. Std of Reward: 0.08264469799591304.\n",
      "Step: 424000. Mean Reward: -0.023042553191489366. Std of Reward: 0.08309887918101418.\n",
      "Step: 425000. Mean Reward: -0.02239872068230277. Std of Reward: 0.08350978185662292.\n",
      "Step: 426000. Mean Reward: -0.02295503211991435. Std of Reward: 0.0829207466577802.\n",
      "Step: 427000. Mean Reward: -0.023744493392070486. Std of Reward: 0.08142230102397317.\n",
      "Step: 428000. Mean Reward: -0.022114967462039045. Std of Reward: 0.08251323310322076.\n",
      "Step: 429000. Mean Reward: -0.023278867102396513. Std of Reward: 0.08221094214724906.\n",
      "Step: 430000. Mean Reward: -0.02502159827213823. Std of Reward: 0.0802449649082475.\n",
      "Step: 431000. Mean Reward: -0.02275109170305677. Std of Reward: 0.08223188037168558.\n",
      "Step: 432000. Mean Reward: -0.02456989247311828. Std of Reward: 0.08025549227170303.\n",
      "Step: 433000. Mean Reward: -0.02432754880694143. Std of Reward: 0.08127397413870986.\n",
      "Step: 434000. Mean Reward: -0.023850325379609547. Std of Reward: 0.08100260664308519.\n",
      "Step: 435000. Mean Reward: -0.0238177874186551. Std of Reward: 0.08141616256877701.\n",
      "Step: 436000. Mean Reward: -0.022373626373626374. Std of Reward: 0.08278844325990715.\n",
      "Step: 437000. Mean Reward: -0.022543478260869568. Std of Reward: 0.08221292782126896.\n",
      "Step: 438000. Mean Reward: -0.02496688741721854. Std of Reward: 0.08072142299866826.\n",
      "Step: 439000. Mean Reward: -0.023050108932461878. Std of Reward: 0.08111061662703449.\n",
      "Step: 440000. Mean Reward: -0.021984815618221253. Std of Reward: 0.08204191687901327.\n",
      "Step: 441000. Mean Reward: -0.021864035087719294. Std of Reward: 0.08269733934411228.\n",
      "Step: 442000. Mean Reward: -0.024543478260869566. Std of Reward: 0.08047824618889773.\n",
      "Step: 443000. Mean Reward: -0.021692477876106193. Std of Reward: 0.08246553657242954.\n",
      "Step: 444000. Mean Reward: -0.022637969094922734. Std of Reward: 0.08254101431409143.\n",
      "Step: 445000. Mean Reward: -0.021195372750642677. Std of Reward: 0.08326397690510501.\n",
      "Step: 446000. Mean Reward: -0.024844155844155842. Std of Reward: 0.08042768227566585.\n",
      "Step: 447000. Mean Reward: -0.02208115183246073. Std of Reward: 0.08294632536056001.\n",
      "Step: 448000. Mean Reward: -0.021292428198433425. Std of Reward: 0.08374414360166588.\n",
      "Step: 449000. Mean Reward: -0.02202917771883289. Std of Reward: 0.08249745079326702.\n",
      "Step: 450000. Mean Reward: -0.02273684210526316. Std of Reward: 0.082216877576619.\n",
      "Saved Model\n",
      "INFO:tensorflow:Restoring parameters from ./models/Tennis_Z_4\\model-450000.cptk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/Tennis_Z_4\\model-450000.cptk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 4 variables to const ops.\n",
      "Step: 451000. Mean Reward: -0.02338046272493573. Std of Reward: 0.0818316142376032.\n",
      "Step: 452000. Mean Reward: -0.02143044619422572. Std of Reward: 0.08348653225389059.\n",
      "Step: 453000. Mean Reward: -0.02264030612244898. Std of Reward: 0.08258602940550851.\n",
      "Step: 454000. Mean Reward: -0.023280423280423283. Std of Reward: 0.08219270612106268.\n",
      "Step: 455000. Mean Reward: -0.024373368146214103. Std of Reward: 0.08116682701520149.\n",
      "Step: 456000. Mean Reward: -0.02198684210526316. Std of Reward: 0.08319997998181893.\n",
      "Step: 457000. Mean Reward: -0.02414021164021164. Std of Reward: 0.08117149147654389.\n",
      "Step: 458000. Mean Reward: -0.023956185567010308. Std of Reward: 0.08152820736260169.\n",
      "Step: 459000. Mean Reward: -0.02318537859007833. Std of Reward: 0.08185215351019268.\n",
      "Step: 460000. Mean Reward: -0.02227034120734908. Std of Reward: 0.08218291733996945.\n",
      "Step: 461000. Mean Reward: -0.02195822454308094. Std of Reward: 0.08265394421937816.\n",
      "Step: 462000. Mean Reward: -0.024776902887139112. Std of Reward: 0.08085023964899722.\n",
      "Step: 463000. Mean Reward: -0.022200520833333334. Std of Reward: 0.08278502783149902.\n",
      "Step: 464000. Mean Reward: -0.022664907651715038. Std of Reward: 0.08246864668910785.\n",
      "Step: 465000. Mean Reward: -0.02125. Std of Reward: 0.08360217052604955.\n",
      "Step: 466000. Mean Reward: -0.022984496124031008. Std of Reward: 0.08213877000179397.\n",
      "Step: 467000. Mean Reward: -0.0245974025974026. Std of Reward: 0.0806396924178999.\n",
      "Step: 468000. Mean Reward: -0.02381510416666667. Std of Reward: 0.08150218671011729.\n",
      "Step: 469000. Mean Reward: -0.023552971576227388. Std of Reward: 0.08156360628990542.\n",
      "Step: 470000. Mean Reward: -0.021885026737967914. Std of Reward: 0.08296673284973106.\n",
      "Step: 471000. Mean Reward: -0.023485639686684077. Std of Reward: 0.0815226613326177.\n",
      "Step: 472000. Mean Reward: -0.022480417754569187. Std of Reward: 0.08284503138324444.\n",
      "Step: 473000. Mean Reward: -0.025714285714285714. Std of Reward: 0.07963436854186279.\n",
      "Step: 474000. Mean Reward: -0.022649350649350652. Std of Reward: 0.08286427115858366.\n",
      "Step: 475000. Mean Reward: -0.02568241469816273. Std of Reward: 0.0796967278557573.\n",
      "Step: 476000. Mean Reward: -0.025130548302872063. Std of Reward: 0.080487555961853.\n",
      "Step: 477000. Mean Reward: -0.02299738219895288. Std of Reward: 0.08217141446028334.\n",
      "Step: 478000. Mean Reward: -0.023015665796344648. Std of Reward: 0.08198208595643444.\n",
      "Step: 479000. Mean Reward: -0.021843501326259944. Std of Reward: 0.08286111813200171.\n",
      "Step: 480000. Mean Reward: -0.021966145833333336. Std of Reward: 0.08260198178955555.\n",
      "Step: 481000. Mean Reward: -0.022630208333333336. Std of Reward: 0.08246753606191508.\n",
      "Step: 482000. Mean Reward: -0.022174479166666667. Std of Reward: 0.08307461364352169.\n",
      "Step: 483000. Mean Reward: -0.022662337662337665. Std of Reward: 0.08244511915484999.\n",
      "Step: 484000. Mean Reward: -0.022194805194805194. Std of Reward: 0.08283915552019898.\n",
      "Step: 485000. Mean Reward: -0.025671052631578945. Std of Reward: 0.07950056076563147.\n",
      "Step: 486000. Mean Reward: -0.02060880829015544. Std of Reward: 0.08441672675845065.\n",
      "Step: 487000. Mean Reward: -0.025076726342710996. Std of Reward: 0.08046814270446526.\n",
      "Step: 488000. Mean Reward: -0.02490909090909091. Std of Reward: 0.08041486291162618.\n",
      "Step: 489000. Mean Reward: -0.02479166666666667. Std of Reward: 0.08071592633358604.\n",
      "Step: 490000. Mean Reward: -0.020884615384615383. Std of Reward: 0.0846280672313483.\n",
      "Step: 491000. Mean Reward: -0.022783505154639175. Std of Reward: 0.08278486922911035.\n",
      "Step: 492000. Mean Reward: -0.022984496124031008. Std of Reward: 0.08217493954888186.\n",
      "Step: 493000. Mean Reward: -0.02204724409448819. Std of Reward: 0.08264656351542345.\n",
      "Step: 494000. Mean Reward: -0.02389763779527559. Std of Reward: 0.08138663770896053.\n",
      "Step: 495000. Mean Reward: -0.024610389610389614. Std of Reward: 0.08078778611623474.\n",
      "Step: 496000. Mean Reward: -0.02337662337662338. Std of Reward: 0.081863211686077.\n",
      "Step: 497000. Mean Reward: -0.02344240837696335. Std of Reward: 0.08127780608345053.\n",
      "Step: 498000. Mean Reward: -0.02395348837209302. Std of Reward: 0.08100389442245275.\n",
      "Step: 499000. Mean Reward: -0.022728459530026116. Std of Reward: 0.08224333061266445.\n",
      "Step: 500000. Mean Reward: -0.02316489361702128. Std of Reward: 0.0813570698224504.\n",
      "Saved Model\n",
      "INFO:tensorflow:Restoring parameters from ./models/Tennis_Z_4\\model-500000.cptk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/Tennis_Z_4\\model-500000.cptk\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "if curriculum_file == \"None\":\n",
    "    curriculum_file = None\n",
    "\n",
    "\n",
    "def get_progress():\n",
    "    if curriculum_file is not None:\n",
    "        if env._curriculum.measure_type == \"progress\":\n",
    "            return steps / max_steps\n",
    "        elif env._curriculum.measure_type == \"reward\":\n",
    "            return last_reward\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create the Tensorflow model graph\n",
    "ppo_model = create_agent_model(env, lr=learning_rate,\n",
    "                               h_size=hidden_units, epsilon=epsilon,\n",
    "                               beta=beta, max_step=max_steps, \n",
    "                               normalize=normalize, num_layers=num_layers)\n",
    "\n",
    "is_continuous = (env.brains[brain_name].action_space_type == \"continuous\")\n",
    "use_observations = (env.brains[brain_name].number_observations > 0)\n",
    "use_states = (env.brains[brain_name].state_space_size > 0)\n",
    "\n",
    "model_path = './models/{}'.format(run_path)\n",
    "summary_path = './summaries/{}'.format(run_path)\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "if not os.path.exists(summary_path):\n",
    "    os.makedirs(summary_path)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "#config.gpu_options.allow_growth = True\n",
    "\n",
    "with tf.Session(config = config) as sess:\n",
    "    # Instantiate model parameters\n",
    "    if load_model:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(model_path)\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        sess.run(init)\n",
    "    steps, last_reward = sess.run([ppo_model.global_step, ppo_model.last_reward])    \n",
    "    summary_writer = tf.summary.FileWriter(summary_path)\n",
    "    info = env.reset(train_mode=train_model, progress=get_progress())[brain_name]\n",
    "    trainer = Trainer(ppo_model, sess, info, is_continuous, use_observations, use_states, train_model)\n",
    "    if train_model:\n",
    "        trainer.write_text(summary_writer, 'Hyperparameters', hyperparameter_dict, steps)\n",
    "    while steps <= max_steps:\n",
    "        if env.global_done:\n",
    "            info = env.reset(train_mode=train_model, progress=get_progress())[brain_name]\n",
    "        # Decide and take an action\n",
    "        new_info = trainer.take_action(info, env, brain_name, steps, normalize)\n",
    "        info = new_info\n",
    "        trainer.process_experiences(info, time_horizon, gamma, lambd)\n",
    "        if len(trainer.training_buffer['actions']) > buffer_size and train_model:\n",
    "            # Perform gradient descent with experience buffer\n",
    "            trainer.update_model(batch_size, num_epoch)\n",
    "        if steps % summary_freq == 0 and steps != 0 and train_model:\n",
    "            # Write training statistics to tensorboard.\n",
    "            trainer.write_summary(summary_writer, steps, env._curriculum.lesson_number)\n",
    "        if steps % save_freq == 0 and steps != 0 and train_model:\n",
    "            # Save Tensorflow model\n",
    "            save_model(sess, model_path=model_path, steps=steps, saver=saver)\n",
    "            export_graph(model_path, env_name+\"_\"+str(steps))\n",
    "        steps += 1\n",
    "        sess.run(ppo_model.increment_step)\n",
    "        if len(trainer.stats['cumulative_reward']) > 0:\n",
    "            mean_reward = np.mean(trainer.stats['cumulative_reward'])\n",
    "            sess.run(ppo_model.update_reward, feed_dict={ppo_model.new_reward: mean_reward})\n",
    "            last_reward = sess.run(ppo_model.last_reward)\n",
    "    # Final save Tensorflow model\n",
    "    if steps != 0 and train_model:\n",
    "        save_model(sess, model_path=model_path, steps=steps, saver=saver)\n",
    "env.close()\n",
    "export_graph(model_path, env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the trained Tensorflow graph\n",
    "Once the model has been trained and saved, we can export it as a .bytes file which Unity can embed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/Tennis_Z_2\\model-100000.cptk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/Tennis_Z_2\\model-100000.cptk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 4 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 4 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "export_graph(model_path, env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
